{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from ete3 import Tree\n",
    "\n",
    "class TreeEncoder:\n",
    "\n",
    "    def encode_tree(self, tree_str):\n",
    "        \"\"\"\n",
    "        Encode the tree structure into a format suitable for input into the neural network.\n",
    "        \"\"\"\n",
    "        # Check if the tree is already encoded\n",
    "        csv_file = tree_str[:-4] + '.csv'\n",
    "        if os.path.exists(csv_file):\n",
    "            return csv_file\n",
    "        # Call the external script to get CDV encoding\n",
    "        cmd = f\"python -m CDV_full_tree -t {tree_str} > {tree_str[:-4]}.csv\"\n",
    "        os.system(cmd)\n",
    "\n",
    "    def encode_all_trees(self, trees_directory):\n",
    "        \"\"\"\n",
    "        Encode all the trees in the given directory.\n",
    "        \"\"\"\n",
    "        tree_files = [os.path.join(trees_directory, file) for file in os.listdir(trees_directory) if file.endswith('.nwk')]\n",
    "        for tree_file in tree_files:\n",
    "            print(tree_file)\n",
    "            self.encode_tree(tree_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trees/bd.nwk\n",
      "trees/bisse.nwk\n",
      "trees/bisseness.nwk\n",
      "trees/classe.nwk\n",
      "trees/geosse.nwk\n",
      "trees/musse.nwk\n"
     ]
    }
   ],
   "source": [
    "trees_directory = \"trees/\"\n",
    "encoder = TreeEncoder()\n",
    "encoded_trees = encoder.encode_all_trees(trees_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(236, 11)\n",
      "(236, 11)\n",
      "           lambda1   lambda2   lambda3       mu1       mu2       mu3  \\\n",
      "0                                                                      \n",
      "0.581637  0.639470  0.694643  0.076380  0.339707  0.246269  0.191005   \n",
      "0.171136  0.455613  0.551331  0.150403  0.076921  0.364527  0.860820   \n",
      "0.587373  0.688031  0.478535  0.045761  0.677784  0.630738  0.375229   \n",
      "0.267792  0.690626  0.640356  0.712357  0.443546  0.298779  0.660996   \n",
      "0.454680  0.469158  0.566001  0.275795  0.631396  0.581336  0.173862   \n",
      "\n",
      "               q12       q13       q21       q23       q31  \n",
      "0                                                           \n",
      "0.581637  0.143894  0.154783  0.627744  0.460762  0.606042  \n",
      "0.171136  0.827794  0.251758  0.249944  0.578592  0.771593  \n",
      "0.587373  0.631197  0.194841  0.177321  0.117500  0.329491  \n",
      "0.267792  0.771743  0.765116  0.413921  0.564865  0.321370  \n",
      "0.454680  0.273638  0.850283  0.287332  0.651840  0.670395  \n",
      "           lambda1   lambda2   lambda3       mu1       mu2       mu3  \\\n",
      "0                                                                      \n",
      "0.581637  0.639470  0.694643  0.076380  0.339707  0.246269  0.191005   \n",
      "0.171136  0.455613  0.551331  0.150403  0.076921  0.364527  0.860820   \n",
      "0.587373  0.688031  0.478535  0.045761  0.677784  0.630738  0.375229   \n",
      "0.267792  0.690626  0.640356  0.712357  0.443546  0.298779  0.660996   \n",
      "0.454680  0.469158  0.566001  0.275795  0.631396  0.581336  0.173862   \n",
      "\n",
      "               q12       q13       q21       q23       q31  \n",
      "0                                                           \n",
      "0.581637  0.143894  0.154783  0.627744  0.460762  0.606042  \n",
      "0.171136  0.827794  0.251758  0.249944  0.578592  0.771593  \n",
      "0.587373  0.631197  0.194841  0.177321  0.117500  0.329491  \n",
      "0.267792  0.771743  0.765116  0.413921  0.564865  0.321370  \n",
      "0.454680  0.273638  0.850283  0.287332  0.651840  0.670395  \n",
      "(237, 502)\n",
      "(237, 502)\n",
      "             1          2          3          4          5          6    \\\n",
      "0                                                                         \n",
      "Index   0.000000   1.000000   2.000000   3.000000   4.000000   5.000000   \n",
      "0       7.743853   6.648208   5.721072   5.693300   6.783453   4.758588   \n",
      "1       5.928847   4.708325   4.516767   4.709624   5.595005   4.175818   \n",
      "2       6.042367   1.403993   5.092303   5.867678   5.996965   0.000000   \n",
      "3      10.877998  10.215666  10.675867  10.160885  10.112411  10.656010   \n",
      "\n",
      "            7          8         9         10   ...    493    494    495  \\\n",
      "0                                               ...                        \n",
      "Index  6.000000   7.000000  8.000000  9.000000  ...  492.0  493.0  494.0   \n",
      "0      2.604404   3.082454  7.502171  7.683798  ...    0.0    0.0    0.0   \n",
      "1      4.114849   2.218430  2.108353  5.286968  ...    0.0    0.0    0.0   \n",
      "2      5.290625   5.884315  5.859049  6.028741  ...    0.0    0.0    0.0   \n",
      "3      9.985865  10.306910  9.385767  9.170996  ...    0.0    0.0    0.0   \n",
      "\n",
      "         496    497    498    499    500    501         502  \n",
      "0                                                            \n",
      "Index  495.0  496.0  497.0  498.0  499.0  500.0  501.000000  \n",
      "0        0.0    0.0    0.0    0.0    0.0    0.0    0.672283  \n",
      "1        0.0    0.0    0.0    0.0    0.0    0.0    1.336636  \n",
      "2        0.0    0.0    0.0    0.0    0.0    0.0    2.388216  \n",
      "3        0.0    0.0    0.0    0.0    0.0    0.0    1.008681  \n",
      "\n",
      "[5 rows x 502 columns]\n"
     ]
    },
    {
     "ename": "SyntaxError",
     "evalue": "'return' outside function (2037089225.py, line 81)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[194], line 81\u001b[1;36m\u001b[0m\n\u001b[1;33m    return\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m 'return' outside function\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load parameter values as a dataframe\n",
    "tree_files = [os.path.join(trees_directory, file) for file in os.listdir(trees_directory) if file.endswith('.nwk')]\n",
    "\n",
    "def process_params_musse(param_file):\n",
    "    # Reads the parameter file and saves the values in a csv file, one tree per row.\n",
    "    '''\n",
    "    Example:\n",
    "    num_states 3\n",
    "    lambda1  0.581637403143104\n",
    "    lambda2  0.639469627428334\n",
    "    lambda3  0.694642654564232\n",
    "    mu1  0.076379950507544\n",
    "    mu2  0.339707092673052\n",
    "    mu3  0.246268530318048\n",
    "    q12  0.191004574298859\n",
    "    q13  0.143894099444151\n",
    "    q21  0.154783235490322\n",
    "    q23  0.62774416487664\n",
    "    q31  0.460761926881969\n",
    "    q32  0.606042030081153\n",
    "    num_states 3\n",
    "    ....\n",
    "    '''\n",
    "    # If the parameter file is already in the csv format, return\n",
    "    if param_file.endswith('.csv'):\n",
    "        return\n",
    "    with open(param_file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    param_values = []\n",
    "    for line in lines:\n",
    "        if line.startswith('num_states'):\n",
    "            param_values.append([])\n",
    "        else:\n",
    "            param_values[-1].append(line.split()[1])\n",
    "    param_df = pd.DataFrame(param_values)\n",
    "    param_df.to_csv(param_file + '.csv', sep='\\t', header=False, index=False)\n",
    "        \n",
    "        \n",
    "    \n",
    "\n",
    "# Create a dataframe to store the parameter values\n",
    "\n",
    "process_params_musse(param_file=trees_directory + 'musse.params')\n",
    "\n",
    "cutoff = 250  # Number of trees to process\n",
    "\n",
    "param_train = pd.read_csv(trees_directory + 'musse.params.csv', nrows=cutoff, header=None, sep='\\t', index_col=0)\n",
    "param_test = pd.read_csv(trees_directory + 'musse.params.csv', sep='\\t', header=None, index_col=0)\n",
    "\n",
    "print(param_train.shape)\n",
    "print(param_test.shape)\n",
    "\n",
    "column_names = ['lambda1', 'lambda2', 'lambda3', 'mu1', 'mu2', 'mu3', 'q12', 'q13', 'q21', 'q23', 'q31', 'q32']\n",
    "\n",
    "def rename_columns(df, names):\n",
    "    df = df.rename(columns={i: names[int(i)-1] for i in df.columns})\n",
    "    return df\n",
    "\n",
    "param_train = rename_columns(param_train, column_names)\n",
    "param_test = rename_columns(param_test, column_names)\n",
    "\n",
    "print(param_train.head())\n",
    "print(param_test.head())\n",
    "\n",
    "# loading tree encodings/representations\n",
    "# encoding has the following structure: 1 value of tree height, 500 values for tip states ('1' or '2')\n",
    "# 1 value for tree height and 500 values for internal node heights\n",
    "# + 2 values for nb of tips of each type (to be removed) and 1 value of rescaling (removed, but stocked for rescaling predicted values back to the original scale)\n",
    "\n",
    "encoding_train = pd.read_csv(trees_directory + 'musse.csv', sep=\"\\t\", header=None, nrows=cutoff, index_col=0)\n",
    "encoding_test = pd.read_csv(trees_directory + 'musse.csv', sep=\"\\t\", header=None, index_col=0)\n",
    "\n",
    "print(encoding_train.shape)\n",
    "print(encoding_test.shape)\n",
    "\n",
    "print(encoding_train.head())\n",
    "\n",
    "\n",
    "return\n",
    "encoded_tree_files = [os.path.join(trees_directory, file) for file in os.listdir(trees_directory) if file.endswith('.csv')]\n",
    "encoded_trees = pd.DataFrame()\n",
    "for encoded_tree_file in encoded_tree_files:\n",
    "    encoded_tree = pd.read_csv(encoded_tree_file, sep=\"\\t\", header=None, index_col=0, skiprows=1)  # Skip the header row\n",
    "    encoded_trees = pd.concat([encoded_trees, encoded_tree], ignore_index=True)\n",
    "\n",
    "# make sure there is correspondance between indexes of dataframe with parameter values and encodings\n",
    "print(param_df.shape)\n",
    "print(encoded_trees.shape)\n",
    "param_df.index = encoded_trees.index\n",
    "\n",
    "# split the data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(encoded_trees, param_df, test_size=0.2, random_state=42)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "\n",
    "# part of the relative path for writing down the output files\n",
    "chemin = \"trained_models/musse/\"\n",
    "\n",
    "# the suffix of output files\n",
    "expname='_245_longest_absolute_error'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "#correctly reshape parameters (rescaling) and encodings (remove nb of each type + rescale factor):\n",
    "\n",
    "### TRAINING SET: PARAMETER VALUES\n",
    "# norm the parameters\n",
    "y_train_norm = y_train.copy()\n",
    "y_train_norm['lambda1'] = y_train['lambda1'] / y_train['lambda1'].max()\n",
    "y_train_norm['lambda2'] = y_train['lambda2'] / y_train['lambda2'].max()\n",
    "y_train_norm['lambda3'] = y_train['lambda3'] / y_train['lambda3'].max()\n",
    "y_train_norm['mu1'] = y_train['mu1'] / y_train['mu1'].max()\n",
    "y_train_norm['mu2'] = y_train['mu2'] / y_train['mu2'].max()\n",
    "y_train_norm['mu3'] = y_train['mu3'] / y_train['mu3'].max()\n",
    "y_train_norm['q12'] = y_train['q12'] / y_train['q12'].max()\n",
    "y_train_norm['q13'] = y_train['q13'] / y_train['q13'].max()\n",
    "y_train_norm['q21'] = y_train['q21'] / y_train['q21'].max()\n",
    "y_train_norm['q23'] = y_train['q23'] / y_train['q23'].max()\n",
    "y_train_norm['q31'] = y_train['q31'] / y_train['q31'].max()\n",
    "y_train_norm['q32'] = y_train['q32'] / y_train['q32'].max()\n",
    "\n",
    "# save the normed parameters\n",
    "y_train_norm.to_csv(chemin + 'y_train_norm' + expname + '.csv')\n",
    "\n",
    "### TESTING SET: PARAMETER VALUES\n",
    "# norm the parameters\n",
    "y_test_norm = y_test.copy()\n",
    "y_test_norm['lambda1'] = y_test['lambda1'] / y_test['lambda1'].max()\n",
    "y_test_norm['lambda2'] = y_test['lambda2'] / y_test['lambda2'].max()\n",
    "y_test_norm['lambda3'] = y_test['lambda3'] / y_test['lambda3'].max()\n",
    "y_test_norm['mu1'] = y_test['mu1'] / y_test['mu1'].max()\n",
    "y_test_norm['mu2'] = y_test['mu2'] / y_test['mu2'].max()\n",
    "y_test_norm['mu3'] = y_test['mu3'] / y_test['mu3'].max()\n",
    "y_test_norm['q12'] = y_test['q12'] / y_test['q12'].max()\n",
    "y_test_norm['q13'] = y_test['q13'] / y_test['q13'].max()\n",
    "y_test_norm['q21'] = y_test['q21'] / y_test['q21'].max()\n",
    "y_test_norm['q23'] = y_test['q23'] / y_test['q23'].max()\n",
    "y_test_norm['q31'] = y_test['q31'] / y_test['q31'].max()\n",
    "y_test_norm['q32'] = y_test['q32'] / y_test['q32'].max()\n",
    "\n",
    "# save the normed parameters\n",
    "y_test_norm.to_csv(chemin + 'y_test_norm' + expname + '.csv')\n",
    "\n",
    "# remove irrelevant columns: count of each type of tip and normalization factor\n",
    "#### X_train = X_train.drop(columns=[1003, 1004, 1005], axis=1, inplace=True)\n",
    "\n",
    "# save the encodings\n",
    "X_train.to_csv(chemin + 'X_train' + expname + '.csv')\n",
    "X_test.to_csv(chemin + 'X_test' + expname + '.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(156, 502)\n",
      "(156, 12)\n",
      "(40, 502)\n",
      "(40, 12)\n"
     ]
    }
   ],
   "source": [
    "# Read the data\n",
    "X_train = pd.read_csv(chemin + 'X_train' + expname + '.csv', index_col=0)\n",
    "X_test = pd.read_csv(chemin + 'X_test' + expname + '.csv', index_col=0)\n",
    "y_train_norm = pd.read_csv(chemin + 'y_train_norm' + expname + '.csv', index_col=0)\n",
    "y_test_norm = pd.read_csv(chemin + 'y_test_norm' + expname + '.csv', index_col=0)\n",
    "\n",
    "\n",
    "#Choice of the parameters to predict\n",
    "\n",
    "predict_all = True\n",
    "if not predict_all:\n",
    "    target1 = 'lambda1'\n",
    "    target2 = 'lambda2'\n",
    "    target3 = 'lambda3'\n",
    "    target4 = 'mu1'\n",
    "    target5 = 'mu2'\n",
    "    target6 = 'mu3'\n",
    "    target7 = 'q12'\n",
    "    target8 = 'q13'\n",
    "    target9 = 'q21'\n",
    "    target10 = 'q23'\n",
    "    target11 = 'q31'\n",
    "    target12 = 'q32'\n",
    "    \n",
    "    targets = pd.DataFrame(y_train_norm[target1, target2, target3, target4, target5, target6, target7, target8, target9, target10, target11, target12])\n",
    "    targets_test = pd.DataFrame(y_test_norm[target1, target2, target3, target4, target5, target6, target7, target8, target9, target10, target11, target12])\n",
    "    \n",
    "else:\n",
    "    \n",
    "    targets = y_train_norm\n",
    "    targets_test = y_test_norm\n",
    "    \n",
    "features = X_train\n",
    "features_test = X_test\n",
    "\n",
    "# split in train and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(features, targets, test_size=0.2, random_state=42)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_val.shape)\n",
    "print(y_val.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#Add the known sampling fraction as 3*2 matrix into the representation (both train and test sets)\\nadd_target = \"sampling_frac\"\\nadded_targets = pd.DataFrame(param_train[add_target])\\nfeatures[\\'1003\\'] = added_targets\\nfeatures[\\'1004\\'] = added_targets\\nfeatures[\\'1005\\'] = added_targets\\nfeatures[\\'1006\\'] = added_targets\\nfeatures[\\'1007\\'] = added_targets\\nfeatures[\\'1008\\'] = added_targets\\n\\nadded_targets2 = pd.DataFrame(param_test[add_target])\\nfeatures_test[\\'1003\\'] = added_targets2\\nfeatures_test[\\'1004\\'] = added_targets2\\nfeatures_test[\\'1005\\'] = added_targets2\\nfeatures_test[\\'1006\\'] = added_targets2\\nfeatures_test[\\'1007\\'] = added_targets2\\nfeatures_test[\\'1008\\'] = added_targets2\\n'"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    \"\"\"\n",
    "    #Add the known sampling fraction as 3*2 matrix into the representation (both train and test sets)\n",
    "    add_target = \"sampling_frac\"\n",
    "    added_targets = pd.DataFrame(param_train[add_target])\n",
    "    features['1003'] = added_targets\n",
    "    features['1004'] = added_targets\n",
    "    features['1005'] = added_targets\n",
    "    features['1006'] = added_targets\n",
    "    features['1007'] = added_targets\n",
    "    features['1008'] = added_targets\n",
    "\n",
    "    added_targets2 = pd.DataFrame(param_test[add_target])\n",
    "    features_test['1003'] = added_targets2\n",
    "    features_test['1004'] = added_targets2\n",
    "    features_test['1005'] = added_targets2\n",
    "    features_test['1006'] = added_targets2\n",
    "    features_test['1007'] = added_targets2\n",
    "    features_test['1008'] = added_targets2\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(196, 502)\n",
      "(196, 12)\n",
      "(49, 502)\n"
     ]
    }
   ],
   "source": [
    "# explore the data\n",
    "print(features.shape)\n",
    "print(targets.shape)\n",
    "print(features_test.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
