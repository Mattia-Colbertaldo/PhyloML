{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from ete3 import Tree\n",
    "\n",
    "class TreeEncoder:\n",
    "\n",
    "    def encode_tree(self, tree_str):\n",
    "        \"\"\"\n",
    "        Encode the tree structure into a format suitable for input into the neural network.\n",
    "        \"\"\"\n",
    "        # Check if the tree is already encoded\n",
    "        csv_file = tree_str[:-4] + '.csv'\n",
    "        if os.path.exists(csv_file):\n",
    "            return csv_file\n",
    "        # Call the external script to get CDV encoding\n",
    "        cmd = f\"python -m CDV_full_tree -t {tree_str} > {tree_str[:-4]}.csv\"\n",
    "        os.system(cmd)\n",
    "\n",
    "    def encode_all_trees(self, trees_directory):\n",
    "        \"\"\"\n",
    "        Encode all the trees in the given directory.\n",
    "        \"\"\"\n",
    "        tree_files = [os.path.join(trees_directory, file) for file in os.listdir(trees_directory) if file.endswith('.nwk')]\n",
    "        for tree_file in tree_files:\n",
    "            print(tree_file)\n",
    "            self.encode_tree(tree_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trees/bd.nwk\n",
      "trees/bisse.nwk\n",
      "trees/bisseness.nwk\n",
      "trees/classe.nwk\n",
      "trees/geosse.nwk\n",
      "trees/musse.nwk\n"
     ]
    }
   ],
   "source": [
    "trees_directory = \"trees/\"\n",
    "encoder = TreeEncoder()\n",
    "encoded_trees = encoder.encode_all_trees(trees_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(236, 11)\n",
      "(236, 11)\n",
      "(236, 502)\n",
      "(236, 502)\n",
      "(236, 502)\n",
      "           lambda1   lambda2   lambda3       mu1       mu2       mu3  \\\n",
      "0                                                                      \n",
      "0.581637  0.639470  0.694643  0.076380  0.339707  0.246269  0.191005   \n",
      "0.171136  0.455613  0.551331  0.150403  0.076921  0.364527  0.860820   \n",
      "0.587373  0.688031  0.478535  0.045761  0.677784  0.630738  0.375229   \n",
      "0.267792  0.690626  0.640356  0.712357  0.443546  0.298779  0.660996   \n",
      "0.454680  0.469158  0.566001  0.275795  0.631396  0.581336  0.173862   \n",
      "...            ...       ...       ...       ...       ...       ...   \n",
      "0.590268  0.446474  0.108840  0.420470  0.245711  0.066488  0.631408   \n",
      "0.236107  0.232584  0.503103  0.162354  0.174115  0.307665  0.262108   \n",
      "0.541853  0.543207  0.455826  0.161908  0.443541  0.190180  0.409562   \n",
      "0.729897  0.390473  0.592883  0.200846  0.711841  0.557205  0.468335   \n",
      "0.152324  0.431591  0.658767  0.241526  0.250550  0.303597  0.747699   \n",
      "\n",
      "               q12       q13       q21       q23       q31  \n",
      "0                                                           \n",
      "0.581637  0.143894  0.154783  0.627744  0.460762  0.606042  \n",
      "0.171136  0.827794  0.251758  0.249944  0.578592  0.771593  \n",
      "0.587373  0.631197  0.194841  0.177321  0.117500  0.329491  \n",
      "0.267792  0.771743  0.765116  0.413921  0.564865  0.321370  \n",
      "0.454680  0.273638  0.850283  0.287332  0.651840  0.670395  \n",
      "...            ...       ...       ...       ...       ...  \n",
      "0.590268  0.797918  0.795014  0.168037  0.435647  0.772686  \n",
      "0.236107  0.241801  0.318561  0.132390  0.796582  0.721440  \n",
      "0.541853  0.301433  0.858756  0.853046  0.113840  0.420640  \n",
      "0.729897  0.129607  0.617470  0.513272  0.793662  0.614994  \n",
      "0.152324  0.808296  0.762765  0.262473  0.331003  0.428999  \n",
      "\n",
      "[236 rows x 11 columns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>493</th>\n",
       "      <th>494</th>\n",
       "      <th>495</th>\n",
       "      <th>496</th>\n",
       "      <th>497</th>\n",
       "      <th>498</th>\n",
       "      <th>499</th>\n",
       "      <th>500</th>\n",
       "      <th>501</th>\n",
       "      <th>502</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.581637</th>\n",
       "      <td>7.743853</td>\n",
       "      <td>6.648208</td>\n",
       "      <td>5.721072</td>\n",
       "      <td>5.693300</td>\n",
       "      <td>6.783453</td>\n",
       "      <td>4.758588</td>\n",
       "      <td>2.604404</td>\n",
       "      <td>3.082454</td>\n",
       "      <td>7.502171</td>\n",
       "      <td>7.683798</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.672283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.171136</th>\n",
       "      <td>5.928847</td>\n",
       "      <td>4.708325</td>\n",
       "      <td>4.516767</td>\n",
       "      <td>4.709624</td>\n",
       "      <td>5.595005</td>\n",
       "      <td>4.175818</td>\n",
       "      <td>4.114849</td>\n",
       "      <td>2.218430</td>\n",
       "      <td>2.108353</td>\n",
       "      <td>5.286968</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.336636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.587373</th>\n",
       "      <td>6.042367</td>\n",
       "      <td>1.403993</td>\n",
       "      <td>5.092303</td>\n",
       "      <td>5.867678</td>\n",
       "      <td>5.996965</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.290625</td>\n",
       "      <td>5.884315</td>\n",
       "      <td>5.859049</td>\n",
       "      <td>6.028741</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.388216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.267792</th>\n",
       "      <td>10.877998</td>\n",
       "      <td>10.215666</td>\n",
       "      <td>10.675867</td>\n",
       "      <td>10.160885</td>\n",
       "      <td>10.112411</td>\n",
       "      <td>10.656010</td>\n",
       "      <td>9.985865</td>\n",
       "      <td>10.306910</td>\n",
       "      <td>9.385767</td>\n",
       "      <td>9.170996</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.008681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.454680</th>\n",
       "      <td>8.114325</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.245628</td>\n",
       "      <td>7.855954</td>\n",
       "      <td>7.817380</td>\n",
       "      <td>6.996360</td>\n",
       "      <td>8.052058</td>\n",
       "      <td>6.958656</td>\n",
       "      <td>7.644137</td>\n",
       "      <td>7.976313</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.254778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.590268</th>\n",
       "      <td>4.823394</td>\n",
       "      <td>1.999291</td>\n",
       "      <td>4.273489</td>\n",
       "      <td>4.169948</td>\n",
       "      <td>4.319598</td>\n",
       "      <td>1.665775</td>\n",
       "      <td>2.674232</td>\n",
       "      <td>0.161372</td>\n",
       "      <td>2.094921</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.035240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.236107</th>\n",
       "      <td>8.959946</td>\n",
       "      <td>8.457937</td>\n",
       "      <td>7.994788</td>\n",
       "      <td>8.633631</td>\n",
       "      <td>7.806082</td>\n",
       "      <td>7.355732</td>\n",
       "      <td>8.338826</td>\n",
       "      <td>8.903481</td>\n",
       "      <td>7.082018</td>\n",
       "      <td>7.271503</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.145869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.541853</th>\n",
       "      <td>8.076159</td>\n",
       "      <td>5.160960</td>\n",
       "      <td>6.252963</td>\n",
       "      <td>7.246771</td>\n",
       "      <td>8.001399</td>\n",
       "      <td>4.844179</td>\n",
       "      <td>7.561043</td>\n",
       "      <td>7.203715</td>\n",
       "      <td>8.044922</td>\n",
       "      <td>7.123671</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.296773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.729897</th>\n",
       "      <td>5.234708</td>\n",
       "      <td>4.086894</td>\n",
       "      <td>3.420064</td>\n",
       "      <td>2.041144</td>\n",
       "      <td>1.428812</td>\n",
       "      <td>1.819005</td>\n",
       "      <td>5.032112</td>\n",
       "      <td>1.358836</td>\n",
       "      <td>3.938118</td>\n",
       "      <td>3.935702</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.142866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.152324</th>\n",
       "      <td>8.237503</td>\n",
       "      <td>5.525761</td>\n",
       "      <td>2.470628</td>\n",
       "      <td>5.672670</td>\n",
       "      <td>7.943404</td>\n",
       "      <td>7.821575</td>\n",
       "      <td>7.484949</td>\n",
       "      <td>0.957149</td>\n",
       "      <td>6.724317</td>\n",
       "      <td>7.594397</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.173928</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>236 rows Ã— 502 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                1          2          3          4          5          6    \\\n",
       "0                                                                            \n",
       "0.581637   7.743853   6.648208   5.721072   5.693300   6.783453   4.758588   \n",
       "0.171136   5.928847   4.708325   4.516767   4.709624   5.595005   4.175818   \n",
       "0.587373   6.042367   1.403993   5.092303   5.867678   5.996965   0.000000   \n",
       "0.267792  10.877998  10.215666  10.675867  10.160885  10.112411  10.656010   \n",
       "0.454680   8.114325   0.000000   7.245628   7.855954   7.817380   6.996360   \n",
       "...             ...        ...        ...        ...        ...        ...   \n",
       "0.590268   4.823394   1.999291   4.273489   4.169948   4.319598   1.665775   \n",
       "0.236107   8.959946   8.457937   7.994788   8.633631   7.806082   7.355732   \n",
       "0.541853   8.076159   5.160960   6.252963   7.246771   8.001399   4.844179   \n",
       "0.729897   5.234708   4.086894   3.420064   2.041144   1.428812   1.819005   \n",
       "0.152324   8.237503   5.525761   2.470628   5.672670   7.943404   7.821575   \n",
       "\n",
       "               7          8         9         10   ...  493  494  495  496  \\\n",
       "0                                                  ...                       \n",
       "0.581637  2.604404   3.082454  7.502171  7.683798  ...  0.0  0.0  0.0  0.0   \n",
       "0.171136  4.114849   2.218430  2.108353  5.286968  ...  0.0  0.0  0.0  0.0   \n",
       "0.587373  5.290625   5.884315  5.859049  6.028741  ...  0.0  0.0  0.0  0.0   \n",
       "0.267792  9.985865  10.306910  9.385767  9.170996  ...  0.0  0.0  0.0  0.0   \n",
       "0.454680  8.052058   6.958656  7.644137  7.976313  ...  0.0  0.0  0.0  0.0   \n",
       "...            ...        ...       ...       ...  ...  ...  ...  ...  ...   \n",
       "0.590268  2.674232   0.161372  2.094921  0.000000  ...  0.0  0.0  0.0  0.0   \n",
       "0.236107  8.338826   8.903481  7.082018  7.271503  ...  0.0  0.0  0.0  0.0   \n",
       "0.541853  7.561043   7.203715  8.044922  7.123671  ...  0.0  0.0  0.0  0.0   \n",
       "0.729897  5.032112   1.358836  3.938118  3.935702  ...  0.0  0.0  0.0  0.0   \n",
       "0.152324  7.484949   0.957149  6.724317  7.594397  ...  0.0  0.0  0.0  0.0   \n",
       "\n",
       "          497  498  499  500  501       502  \n",
       "0                                            \n",
       "0.581637  0.0  0.0  0.0  0.0  0.0  0.672283  \n",
       "0.171136  0.0  0.0  0.0  0.0  0.0  1.336636  \n",
       "0.587373  0.0  0.0  0.0  0.0  0.0  2.388216  \n",
       "0.267792  0.0  0.0  0.0  0.0  0.0  1.008681  \n",
       "0.454680  0.0  0.0  0.0  0.0  0.0  3.254778  \n",
       "...       ...  ...  ...  ...  ...       ...  \n",
       "0.590268  0.0  0.0  0.0  0.0  0.0  1.035240  \n",
       "0.236107  0.0  0.0  0.0  0.0  0.0  2.145869  \n",
       "0.541853  0.0  0.0  0.0  0.0  0.0  1.296773  \n",
       "0.729897  0.0  0.0  0.0  0.0  0.0  1.142866  \n",
       "0.152324  0.0  0.0  0.0  0.0  0.0  2.173928  \n",
       "\n",
       "[236 rows x 502 columns]"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load parameter values as a dataframe\n",
    "tree_files = [os.path.join(trees_directory, file) for file in os.listdir(trees_directory) if file.endswith('.nwk')]\n",
    "\n",
    "def process_params_musse(param_file):\n",
    "    # Reads the parameter file and saves the values in a csv file, one tree per row.\n",
    "    '''\n",
    "    Example:\n",
    "    num_states 3\n",
    "    lambda1  0.581637403143104\n",
    "    lambda2  0.639469627428334\n",
    "    lambda3  0.694642654564232\n",
    "    mu1  0.076379950507544\n",
    "    mu2  0.339707092673052\n",
    "    mu3  0.246268530318048\n",
    "    q12  0.191004574298859\n",
    "    q13  0.143894099444151\n",
    "    q21  0.154783235490322\n",
    "    q23  0.62774416487664\n",
    "    q31  0.460761926881969\n",
    "    q32  0.606042030081153\n",
    "    num_states 3\n",
    "    ....\n",
    "    '''\n",
    "    # If the parameter file is already in the csv format, return\n",
    "    if param_file.endswith('.csv'):\n",
    "        return\n",
    "    with open(param_file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    param_values = []\n",
    "    for line in lines:\n",
    "        if line.startswith('num_states'):\n",
    "            param_values.append([])\n",
    "        else:\n",
    "            param_values[-1].append(line.split()[1])\n",
    "    param_df = pd.DataFrame(param_values)\n",
    "    param_df.to_csv(param_file + '.csv', sep='\\t', header=False, index=False)\n",
    "        \n",
    "        \n",
    "    \n",
    "\n",
    "# Create a dataframe to store the parameter values\n",
    "\n",
    "process_params_musse(param_file=trees_directory + 'musse.params')\n",
    "\n",
    "cutoff = 250  # Number of trees to process\n",
    "\n",
    "param_train = pd.read_csv(trees_directory + 'musse.params.csv', nrows=cutoff, header=None, sep='\\t', index_col=0)\n",
    "param_test = pd.read_csv(trees_directory + 'musse.params.csv', sep='\\t', header=None, index_col=0)\n",
    "\n",
    "print(param_train.shape)\n",
    "print(param_test.shape)\n",
    "\n",
    "column_names = ['lambda1', 'lambda2', 'lambda3', 'mu1', 'mu2', 'mu3', 'q12', 'q13', 'q21', 'q23', 'q31', 'q32']\n",
    "\n",
    "def rename_columns(df, names):\n",
    "    df = df.rename(columns={i: names[int(i)-1] for i in df.columns})\n",
    "    return df\n",
    "\n",
    "param_train = rename_columns(param_train, column_names)\n",
    "param_test = rename_columns(param_test, column_names)\n",
    "\n",
    "# loading tree encodings/representations\n",
    "# encoding has the following structure: 1 value of tree height, 500 values for tip states ('1' or '2')\n",
    "# 1 value for tree height and 500 values for internal node heights\n",
    "# + 2 values for nb of tips of each type (to be removed) and 1 value of rescaling (removed, but stocked for rescaling predicted values back to the original scale)\n",
    "\n",
    "encoding_train = pd.read_csv(trees_directory + 'musse.csv', sep=\"\\t\", header=None, nrows=cutoff, index_col=0, skiprows=1)\n",
    "encoding_test = pd.read_csv(trees_directory + 'musse.csv', sep=\"\\t\", header=None, index_col=0, skiprows=1)\n",
    "\n",
    "print(encoding_train.shape)\n",
    "print(encoding_test.shape)\n",
    "\n",
    "\n",
    "\n",
    "# make sure there is correspondance between indexes of dataframe with parameter values and encodings\n",
    "encoding_train.index = param_train.index\n",
    "encoding_test.index = param_test.index\n",
    "\n",
    "\n",
    "# part of the relative path for writing down the output files\n",
    "chemin = './trained_models/musse'\n",
    "\n",
    "# the suffix of output files\n",
    "expname='_236_longest_known_nb_tips_absolute_error'\n",
    "\n",
    "# check\n",
    "param_test\n",
    "\n",
    "# check\n",
    "print(encoding_test.shape)\n",
    "print(param_train)\n",
    "\n",
    "# check\n",
    "encoding_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "505",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\matti\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:2606\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:2630\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 505",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[208], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#correctly reshape parameters (rescaling) and encodings (remove nb of each type + rescale factor):\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m### TRAINING SET: PARAMETER VALUES\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# rescaling factor\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m param_train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnorm_factor\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mencoding_train\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m505\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# rescale target values according to scaling factor\u001b[39;00m\n\u001b[0;32m      7\u001b[0m param_train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnet_rat1_rescaled\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m param_train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnet_rate1\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m*\u001b[39mparam_train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnorm_factor\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\matti\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:4090\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4088\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4089\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4090\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4092\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\matti\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 505"
     ]
    }
   ],
   "source": [
    "#correctly reshape parameters (rescaling) and encodings (remove nb of each type + rescale factor):\n",
    "\n",
    "### TRAINING SET: PARAMETER VALUES\n",
    "# rescaling factor\n",
    "param_train['norm_factor'] = encoding_train[1005]\n",
    "# rescale target values according to scaling factor\n",
    "param_train['net_rat1_rescaled'] = param_train['net_rate1']*param_train['norm_factor']\n",
    "param_train['net_rat2_rescaled'] = param_train['net_rate2']*param_train['norm_factor']\n",
    "param_train['lambda1_rescaled'] = param_train['lambda1']*param_train['norm_factor']\n",
    "param_train['lambda2_rescaled'] = param_train['lambda2']*param_train['norm_factor']\n",
    "param_train['q01_rescaled'] = param_train['q01']*param_train['norm_factor']\n",
    "\n",
    "### TESTING SET: PARAMETER VALUES\n",
    "# rescaling factor\n",
    "param_test['norm_factor'] = encoding_test[1005]\n",
    "# rescale target values\n",
    "param_test['net_rat1_rescaled'] = param_test['net_rate1']*param_test['norm_factor']\n",
    "param_test['net_rat2_rescaled'] = param_test['net_rate2']*param_test['norm_factor']\n",
    "param_test['lambda1_rescaled'] = param_test['lambda1']*param_test['norm_factor']\n",
    "param_test['lambda2_rescaled'] = param_test['lambda2']*param_test['norm_factor']\n",
    "param_test['q01_rescaled'] = param_test['q01']*param_test['norm_factor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "#correctly reshape parameters (rescaling) and encodings (remove nb of each type + rescale factor):\n",
    "\n",
    "### TRAINING SET: PARAMETER VALUES\n",
    "# norm the parameters\n",
    "y_train_norm = y_train.copy()\n",
    "y_train_norm['lambda1'] = y_train['lambda1'] / y_train['lambda1'].max()\n",
    "y_train_norm['lambda2'] = y_train['lambda2'] / y_train['lambda2'].max()\n",
    "y_train_norm['lambda3'] = y_train['lambda3'] / y_train['lambda3'].max()\n",
    "y_train_norm['mu1'] = y_train['mu1'] / y_train['mu1'].max()\n",
    "y_train_norm['mu2'] = y_train['mu2'] / y_train['mu2'].max()\n",
    "y_train_norm['mu3'] = y_train['mu3'] / y_train['mu3'].max()\n",
    "y_train_norm['q12'] = y_train['q12'] / y_train['q12'].max()\n",
    "y_train_norm['q13'] = y_train['q13'] / y_train['q13'].max()\n",
    "y_train_norm['q21'] = y_train['q21'] / y_train['q21'].max()\n",
    "y_train_norm['q23'] = y_train['q23'] / y_train['q23'].max()\n",
    "y_train_norm['q31'] = y_train['q31'] / y_train['q31'].max()\n",
    "y_train_norm['q32'] = y_train['q32'] / y_train['q32'].max()\n",
    "\n",
    "# save the normed parameters\n",
    "y_train_norm.to_csv(chemin + 'y_train_norm' + expname + '.csv')\n",
    "\n",
    "### TESTING SET: PARAMETER VALUES\n",
    "# norm the parameters\n",
    "y_test_norm = y_test.copy()\n",
    "y_test_norm['lambda1'] = y_test['lambda1'] / y_test['lambda1'].max()\n",
    "y_test_norm['lambda2'] = y_test['lambda2'] / y_test['lambda2'].max()\n",
    "y_test_norm['lambda3'] = y_test['lambda3'] / y_test['lambda3'].max()\n",
    "y_test_norm['mu1'] = y_test['mu1'] / y_test['mu1'].max()\n",
    "y_test_norm['mu2'] = y_test['mu2'] / y_test['mu2'].max()\n",
    "y_test_norm['mu3'] = y_test['mu3'] / y_test['mu3'].max()\n",
    "y_test_norm['q12'] = y_test['q12'] / y_test['q12'].max()\n",
    "y_test_norm['q13'] = y_test['q13'] / y_test['q13'].max()\n",
    "y_test_norm['q21'] = y_test['q21'] / y_test['q21'].max()\n",
    "y_test_norm['q23'] = y_test['q23'] / y_test['q23'].max()\n",
    "y_test_norm['q31'] = y_test['q31'] / y_test['q31'].max()\n",
    "y_test_norm['q32'] = y_test['q32'] / y_test['q32'].max()\n",
    "\n",
    "# save the normed parameters\n",
    "y_test_norm.to_csv(chemin + 'y_test_norm' + expname + '.csv')\n",
    "\n",
    "# remove irrelevant columns: count of each type of tip and normalization factor\n",
    "#### X_train = X_train.drop(columns=[1003, 1004, 1005], axis=1, inplace=True)\n",
    "\n",
    "# save the encodings\n",
    "X_train.to_csv(chemin + 'X_train' + expname + '.csv')\n",
    "X_test.to_csv(chemin + 'X_test' + expname + '.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(156, 502)\n",
      "(156, 12)\n",
      "(40, 502)\n",
      "(40, 12)\n"
     ]
    }
   ],
   "source": [
    "# Read the data\n",
    "X_train = pd.read_csv(chemin + 'X_train' + expname + '.csv', index_col=0)\n",
    "X_test = pd.read_csv(chemin + 'X_test' + expname + '.csv', index_col=0)\n",
    "y_train_norm = pd.read_csv(chemin + 'y_train_norm' + expname + '.csv', index_col=0)\n",
    "y_test_norm = pd.read_csv(chemin + 'y_test_norm' + expname + '.csv', index_col=0)\n",
    "\n",
    "\n",
    "#Choice of the parameters to predict\n",
    "\n",
    "predict_all = True\n",
    "if not predict_all:\n",
    "    target1 = 'lambda1'\n",
    "    target2 = 'lambda2'\n",
    "    target3 = 'lambda3'\n",
    "    target4 = 'mu1'\n",
    "    target5 = 'mu2'\n",
    "    target6 = 'mu3'\n",
    "    target7 = 'q12'\n",
    "    target8 = 'q13'\n",
    "    target9 = 'q21'\n",
    "    target10 = 'q23'\n",
    "    target11 = 'q31'\n",
    "    target12 = 'q32'\n",
    "    \n",
    "    targets = pd.DataFrame(y_train_norm[target1, target2, target3, target4, target5, target6, target7, target8, target9, target10, target11, target12])\n",
    "    targets_test = pd.DataFrame(y_test_norm[target1, target2, target3, target4, target5, target6, target7, target8, target9, target10, target11, target12])\n",
    "    \n",
    "else:\n",
    "    \n",
    "    targets = y_train_norm\n",
    "    targets_test = y_test_norm\n",
    "    \n",
    "features = X_train\n",
    "features_test = X_test\n",
    "\n",
    "# split in train and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(features, targets, test_size=0.2, random_state=42)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_val.shape)\n",
    "print(y_val.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#Add the known sampling fraction as 3*2 matrix into the representation (both train and test sets)\\nadd_target = \"sampling_frac\"\\nadded_targets = pd.DataFrame(param_train[add_target])\\nfeatures[\\'1003\\'] = added_targets\\nfeatures[\\'1004\\'] = added_targets\\nfeatures[\\'1005\\'] = added_targets\\nfeatures[\\'1006\\'] = added_targets\\nfeatures[\\'1007\\'] = added_targets\\nfeatures[\\'1008\\'] = added_targets\\n\\nadded_targets2 = pd.DataFrame(param_test[add_target])\\nfeatures_test[\\'1003\\'] = added_targets2\\nfeatures_test[\\'1004\\'] = added_targets2\\nfeatures_test[\\'1005\\'] = added_targets2\\nfeatures_test[\\'1006\\'] = added_targets2\\nfeatures_test[\\'1007\\'] = added_targets2\\nfeatures_test[\\'1008\\'] = added_targets2\\n'"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    \"\"\"\n",
    "    #Add the known sampling fraction as 3*2 matrix into the representation (both train and test sets)\n",
    "    add_target = \"sampling_frac\"\n",
    "    added_targets = pd.DataFrame(param_train[add_target])\n",
    "    features['1003'] = added_targets\n",
    "    features['1004'] = added_targets\n",
    "    features['1005'] = added_targets\n",
    "    features['1006'] = added_targets\n",
    "    features['1007'] = added_targets\n",
    "    features['1008'] = added_targets\n",
    "\n",
    "    added_targets2 = pd.DataFrame(param_test[add_target])\n",
    "    features_test['1003'] = added_targets2\n",
    "    features_test['1004'] = added_targets2\n",
    "    features_test['1005'] = added_targets2\n",
    "    features_test['1006'] = added_targets2\n",
    "    features_test['1007'] = added_targets2\n",
    "    features_test['1008'] = added_targets2\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(196, 502)\n",
      "(196, 12)\n",
      "(49, 502)\n"
     ]
    }
   ],
   "source": [
    "# explore the data\n",
    "print(features.shape)\n",
    "print(targets.shape)\n",
    "print(features_test.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
